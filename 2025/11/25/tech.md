# 科技新闻 - 2025年11月25日

**归档日期：** 2025-11-26 01:55:17  
**新闻数量：** 4条  
**分类：** 科技

---

## 1. Haberman reveals why Trump attacked judge and his family in speech

**来源：** CNN.com - RSS Channel - App International Edition  
**时间：** Wed, 05 Apr 2023 13:30:09 GMT  
**分类：** tech  
**语言：** en  

### 摘要

CNN political contributor Maggie Haberman explains the reasoning behind Donald Trump's attacks on the judge and his family during a speech at his Mar-a-Lago resort after he was arraigned on felony charges.

### 相关图片

![图片](https://media.cnn.com/api/v1/images/stellar/prod/still-22146807-2173209-3329999996-still.jpg?c=16x9&q=w_250,c_fill)
![图片](https://media.cnn.com/api/v1/images/stellar/prod/still-22148258-4258-667-still.jpg?c=16x9&q=w_250,c_fill)
![图片](https://media.cnn.com/api/v1/images/stellar/prod/jeffries-20251125223457633.jpg?c=16x9&q=w_250,c_fill)
![图片](https://media.cnn.com/api/v1/images/stellar/prod/still-22147630-1969105-9049999998-still.jpg?c=16x9&q=w_250,c_fill)
![图片](https://media.cnn.com/api/v1/images/stellar/prod/sidner-green.jpg?c=16x9&q=w_250,c_fill)

### HTML原始内容

```html
<body class="layout layout--with-bottom-rail politics" data-page-type="video">

<div class="layout__content-wrapper layout-with-bottom-rail__content-wrapper">
<section class="layout__sub-header layout--with-bottom-rail__sub-header" data-editable="subHeader" data-track-zone="subHeader"> <div class="product-zone layout--full-bleed product-zone product-zone--t-dark page-top-full--alert-margin" data-analytics-collection="zone" data-collapsed-text="" data-component-name="product-zone" data-selective-publishing="true" data-uri="cms.cnn.com/_components/product-zone/instances/new-watch-subheader-product-zone-1@published" id="">
<div class="product-zone__outer"></div>
<div class="product-zone__inner has-pseudo-class-fix-layout--full-bleed">
<div class="product-zone__kicker" data-editable="kicker">
</div>
<div class="product-zone__items layout--full-bleed" data-editable="items" data-reorderable-component="items">
<div class="container container_ribbon-dtc entertainment" data-collapsed-text="" data-component-name="container" data-content-recs-called="false" data-layout="container_ribbon-dtc" data-number-of-items="0" data-recs-content-types="" data-recs-dedupe="" data-recs-model="popular" data-recs-sections="" data-selective-publishing="true" data-source="stellar" data-title="" data-uri="cms.cnn.com/_components/container/instances/new-watch-subheader-v1@published">
<div class="container__ads container_ribbon-dtc__ads">
</div>
<div class="container__kicker container__kicker--kicker-text" data-editable="kicker">
</div>
<div class="container_ribbon-dtc__cards-wrapper">
<div class="container__field-wrapper container_ribbon-dtc__field-wrapper">
<ul class="container__field-links container_ribbon-dtc__field-links" data-editable="cards">
<li class="card container__item container__item--type-media-image container__item--type-video container_ribbon-dtc__item container_ribbon-dtc__item--type-video" data-component-name="card" data-created-updated-by="true" data-editable="settings" data-open-link="/watch" data-uri="cms.cnn.com/_components/card/instances/watch-subheader-live@published">
<a class="container__link container__link--type- container_ribbon-dtc__link" data-link-type="" href="/watch">
<div class="container__text container_ribbon-dtc__text">
<div class="container__headline container_ribbon-dtc__headline">
<span class="container__headline-text" data-editable="headline">Featured</span>
</div>
</div>
</a>
</li>
<li class="card container__item container__item--type-media-image container__item--type-video container_ribbon-dtc__item container_ribbon-dtc__item--type-video" data-component-name="card" data-created-updated-by="true" data-editable="settings" data-open-link="/watch#shows-films" data-uri="cms.cnn.com/_components/card/instances/watch-subheader-shows@published">
<a class="container__link container__link--type- container_ribbon-dtc__link" data-link-type="" href="/watch#shows-films">
<div class="container__text container_ribbon-dtc__text">
<div class="container__headline container_ribbon-dtc__headline">
<span class="container__headline-text" data-editable="headline">Shows &amp; Films</span>
</div>
</div>
</a>
</li>
<li class="card container__item container__item--type-media-image container__item--type-video container_ribbon-dtc__item container_ribbon-dtc__item--type-video" data-component-name="card" data-created-updated-by="true" data-editable="settings" data-open-link="/videos/live" data-uri="cms.cnn.com/_components/card/instances/watch-subheader-network@published">
<a class="container__link container__link--type- container_ribbon-dtc__link" data-link-type="" href="/videos/live">
<div class="container__text container_ribbon-dtc__text">
<div class="container__headline container_ribbon-dtc__headline">
<span class="container__headline-text" data-editable="headline">Network TV</span>
</div>
</div>
</a>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section class="layout__info layout-with-bottom-rail__info" data-editable="topLayout" data-track-zone="topLayout"><div class="alerts" data-uri="cms.cnn.com/_components/alerts/instances/cnn-v1@published"></div>
</section>
<section class="layout__info layout-with-bottom-rail__info layout-with-bottom-rail__topFullBleed" data-editable="topFullBleed" data-track-zone="topFullBleed">
</section>
<section class="layout__top layout-with-bottom-rail__top" data-editable="top" data-sticky-anchor-condition-type="pageType,templateType" data-sticky-anchor-condition-value="gallery,gallery_leaf" data-sticky-anchor-pos="bottom" data-track-zone="top"> <div class="headline headline--has-lowertext" data-component-name="headline" data-uri="cms.cnn.com/_components/headline/instances/headline-maggie-haberman-donald-trump-speech-indictment-reaction-sot-cnntm-vpx_h_91e132842140007ce43fbce456e162c8@published">
<div class="headline__wrapper">
<div data-editable="settings"></div>
<h1 class="headline__text inline-placeholder vossi-headline-text" data-editable="headlineText" id="maincontent">
   
```

*（完整HTML内容已保存，长度: 149211 字符）*

### HTML格式

```html
<article class="news-article">
    <header>
        <h1>Haberman reveals why Trump attacked judge and his family in speech</h1>
        <div class="meta">
            <span class="source">CNN.com - RSS Channel - App International Edition</span>
            <time datetime="Wed, 05 Apr 2023 13:30:09 GMT">Wed, 05 Apr 2023 13:30:09 GMT</time>
        </div>
    </header>
    <section class="summary">
        <p>CNN political contributor Maggie Haberman explains the reasoning behind Donald Trump&#39;s attacks on the judge and his family during a speech at his Mar-a-Lago resort after he was arraigned on felony charges.</p>
    </section>
    <section class="content">
        
    </section>
    
    <div class="images">
        <img src="https://media.cnn.com/api/v1/images/stellar/prod/still-22146807-2173209-3329999996-still.jpg?c=16x9&q=w_250,c_fill" alt="新闻图片" />
        <img src="https://media.cnn.com/api/v1/images/stellar/prod/still-22148258-4258-667-still.jpg?c=16x9&q=w_250,c_fill" alt="新闻图片" />
        <img src="https://media.cnn.com/api/v1/images/stellar/prod/jeffries-20251125223457633.jpg?c=16x9&q=w_250,c_fill" alt="新闻图片" />
        <img src="https://media.cnn.com/api/v1/images/stellar/prod/still-22147630-1969105-9049999998-still.jpg?c=16x9&q=w_250,c_fill" alt="新闻图片" />
        <img src="https://media.cnn.com/api/v1/images/stellar/prod/sidner-green.jpg?c=16x9&q=w_250,c_fill" alt="新闻图片" />
        <img src="https://media.cnn.com/api/v1/images/stellar/prod/gettyimages-2246881181-20251123131016465.jpg?c=16x9&q=w_250,c_fill" alt="新闻图片" />
        <img src="https://media.cnn.com/api/v1/images/stellar/prod/115412-tornadoes-tx-wide-cln-00-00-16-10-still001.jpg?c=16x9&q=w_250,c_fill" alt="新闻图片" />
        <img src="https://media.cnn.com/api/v1/images/stellar/prod/2025-10-23t200301z-535979140-rc2thhawzhxd-rtrmadp-3-usa-shutdown.jpg?c=16x9&q=w_250,c_fill" alt="新闻图片" />
        <img src="https://media.cnn.com/api/v1/images/stellar/videothumbnails/40528387-08153870-generated-thumbnail.jpg?c=16x9&q=w_250,c_fill" alt="新闻图片" />
        <img src="https://media.cnn.com/api/v1/images/stellar/prod/carville-20251125025956282.jpg?c=16x9&q=w_250,c_fill" alt="新闻图片" />
        <img src="https://media.cnn.com/api/v1/images/stellar/prod/kashkari.jpg?c=16x9&q=w_250,c_fill" alt="新闻图片" />
        <img src="https://media.cnn.com/api/v1/images/stellar/prod/c-gettyimages-2246881437.jpg?c=16x9&q=w_250,c_fill" alt="新闻图片" />
        <img src="https://media.cnn.com/api/v1/images/stellar/prod/letitiajamesjamescomey.jpg?c=16x9&q=w_250,c_fill" alt="新闻图片" />
        <img src="https://media.cnn.com/api/v1/images/stellar/prod/matthew-rubio-split-still-0.jpg?c=16x9&q=w_250,c_fill" alt="新闻图片" />
        <img src="https://media.cnn.com/api/v1/images/stellar/prod/115383-nicisraelstrikebeirut-digvid-v1.jpg?c=16x9&q=w_250,c_fill" alt="新闻图片" />
        <img src="https://media.cnn.com/api/v1/images/stellar/prod/115382-crime-boss-house-thumbnail.jpg?c=16x9&q=w_250,c_fill" alt="新闻图片" />
        <img src="https://media.cnn.com/api/v1/images/stellar/prod/huntforreal.jpg?c=16x9&q=w_250,c_fill" alt="新闻图片" />
        <img src="https://media.cnn.com/api/v1/images/stellar/prod/115375-intern-detained-by-ice-16x9-00-01-53-26-still001.jpg?c=16x9&q=w_250,c_fill" alt="新闻图片" />
        <img src="https://media.cnn.com/api/v1/images/stellar/prod/still-22142058-2072143-9740000002-still.jpg?c=16x9&q=w_250,c_fill" alt="新闻图片" />
        <img src="https://media.cnn.com/api/v1/images/stellar/prod/115340-tammy-bruce-kfile-digvid-clean-thumb.jpg?c=16x9&q=w_250,c_fill" alt="新闻图片" />
        <img src="https://media.cnn.com/api/v1/images/stellar/prod/ap25322661869304.jpg?c=16x9&q=w_250,c_fill" alt="新闻图片" />
    </div>
    <footer>
        <a href="https://www.cnn.com/videos/politics/2023/04/05/maggie-haberman-donald-trump-speech-indictment-reaction-sot-cnntm-vpx.cnn" target="_blank">阅读原文</a>
    </footer>
</article>
```

**原文链接：** [https://www.cnn.com/videos/politics/2023/04/05/maggie-haberman-donald-trump-speech-indictment-reaction-sot-cnntm-vpx.cnn](https://www.cnn.com/videos/politics/2023/04/05/maggie-haberman-donald-trump-speech-indictment-reaction-sot-cnntm-vpx.cnn)

---

## 2. “光纤之父”高锟离世 曾获诺贝尔物理学奖

**来源：** 国内要闻-新浪新闻  
**时间：** Sun, 23 Sep 2018 10:47:40 GMT  
**分类：** tech  
**语言：** zh  

### 摘要

原标题：”光纤之父”高锟离世 享年84岁
　　据香港媒体报道，香港中文大学前校长、有“光纤之父”之称的高锟，今天（9月23日）下午在医院离世，享年84岁。

　　高锟光纤、宽带传送等科技成就极高，在国际学术领域获奖无数，并在2009年10月6日获得诺贝尔物理学奖，以表扬其“....

### 正文

租用小电充电宝已经及时归还却被收费99元。2月14日晚6点30分左右在南京市碑亭巷俺村活鱼使用支付宝租用小电充电宝，并于当晚7点25分左右归还充电宝，正确插入卡槽，充电宝指示灯亮起。 2月19日早上7点30分左右收到支付宝扣款99元消息。

就算在质保内也不能质保！京东销售方当时购买时并没有给发票及并没告知需要保留外包装！本来不给发票就有逃税嫌疑！要求京东履行质保义务。

上海天津广东河南四川福建江苏河北湖北湖南陕西黑龙江安徽江西海南山东广西

Copyright ©1996-2025 SINA Corporation, All Rights Reserved

隐私保护新浪公司版权所有京ICP证000007

违法和不良信息举报电话：4001102288　举报邮箱：jubao@vip.sina.com

京网文﹝2023﹞4325-128号互联网新闻信息服务许可编号：11220180001北京新浪互联信息服务有限公司

(京)网药械信息备字（2024）第 00220 号　京教研[2002]7号　电信业务审批[2001]字第379号

增值电信业务经营许可证B1.B2-20090108　增值电信业务经营许可证：京ICP证000007号

广播电视节目制作经营许可证（京）字第00828号 甲测资字11110398京公网安备11000002000016号

互联网宗教信息服务许可证：京（2025）0000015

### 相关图片

![图片](https://beacon.sina.com.cn/a.gif?noScript)
![图片](https://i0.sinaimg.cn/cha/images/c.gif)
![图片](https://n.sinaimg.cn/finance/blackcat/pc/blink.gif)
![图片](https://k.sinaimg.cn/n/news/transform/525/w315h210/20251126/3626-42e1925d2279a6600af5b3a25397c0de.jpg/w210h140z1l50t1q100f16de.jpg)
![图片](https://k.sinaimg.cn/n/news/transform/525/w315h210/20251126/f301-3de4fdf63a4045ffbd68266341087b3b.jpg/w210h140z1l50t1q100f17e6.jpg)

### HTML原始内容

```html
<body><!-- body code begin -->
<!-- SUDA_CODE_START -->

<noscript>
<div style="position:absolute;top:0;left:0;width:0;height:0;visibility:hidden"><img alt="" border="0" height="0" src="//beacon.sina.com.cn/a.gif?noScript" width="0"/></div>
</noscript>
<!-- SUDA_CODE_END -->
<!-- SSO_GETCOOKIE_START -->

<!-- SSO_GETCOOKIE_END -->

<!-- body code end -->
<!--头条报-->

<!--头条报-->
<!--飘红0203-->

<!-- 头部 bar begin -->
<div class="top-nav-wrap" id="SI_Top_Wrap">
<div class="top-nav">
<div class="tn-bg">
<div class="tn-header">
<div class="tn-nav">
<div class="tn-title" node-type="sethome">
<a class="tn-tab" href="javascript:;" suda-uatrack="key=index_new_menu&amp;value=set_index"><i>设为首页</i>
</a>
</div>
<div class="tn-title" node-type="menu" style="display:none;">
<a class="tn-tab" href="javascript:;">
<i>
                                            我的菜单
                                            <span class="tn-arrow"> </span> </i>
</a>
<div class="tn-topmenulist tn-topmenulist-a tn-topmenulist-a-menu" node-type="menuList" style="display:none;">
</div>
</div>
<div class="tn-title">
<a class="tn-tab" href="https://sina.cn/" suda-uatrack="key=index_new_menu&amp;value=sina_wap" target="_blank"><i>手机新浪网</i>
</a>
</div>
<div class="tn-title" node-type="client">
<a class="tn-tab" suda-uatrack="key=index_new_menu&amp;value=sina_apps_click" target="_blank"> <i>移动客户端
<em class="tn-new tn-new2" style="display: none; /* display: inline-block; */"></em>
<span class="tn-arrow"> </span></i> </a>
<div class="tn-topmenulist tn-topmenulist-a tn-topmenulist-a-client" node-type="clientList" style="display:none;">
<ul class="tn-text-list">
<li><a href="https://c.weibo.cn/client/guide/download" suda-uatrack="key=index_new_menu&amp;value=sina_apps_list_click" target="_blank">新浪微博</a></li>
<li><a href="https://so.sina.cn/palmnews/web-sinanews-app-download.d.html" suda-uatrack="key=index_new_menu&amp;value=sina_apps_list_click" target="_blank">新浪新闻</a></li>
<li><a href="https://finance.sina.com.cn/mobile/comfinanceweb.shtml" suda-uatrack="key=index_new_menu&amp;value=sina_apps_list_click" target="_blank">新浪财经</a></li>
<li><a href="https://tousu.sina.com.cn/about_app/index?frompage=heimaopc" style="padding-right:12px" suda-uatrack="key=index_new_menu&amp;value=sina_apps_list_click" target="_blank">黑猫投诉</a></li>
<!-- li><a target="_blank" href="https://edu.sina.com.cn/app/download.shtml" suda-uatrack="key=index_new_menu&value=sina_apps_list_click">新浪升学帮</a></li -->
<!-- <li><a target="_blank" href="https://licaishi.sina.com.cn/html5/act/ganggu/index.html"  suda-uatrack="key=index_new_menu&value=sina_apps_list_click">新浪港股通</a></li> -->
<li><a href="http://blog.sina.com.cn/lm/z/app/" suda-uatrack="key=index_new_menu&amp;value=sina_apps_list_click" target="_blank">新浪博客</a></li>
<!-- <li><a target="_blank" href="https://tianqitong.sina.cn/"  suda-uatrack="key=index_new_menu&value=sina_apps_list_click">天气通</a></li> -->
<li><a href="https://zhongce.sina.com.cn/about/app" suda-uatrack="key=index_new_menu&amp;value=sina_apps_list_click" target="_blank">新浪众测</a></li>
<li><a href="https://mail.sina.com.cn/client/mobile/index.php?suda-key=mail_app&amp;suda-value=login" style="padding-right:12px" suda-uatrack="key=index_new_menu&amp;value=sina_apps_list_click" target="_blank">新浪邮箱客户端</a></li>
</ul>
</div>
</div>
</div>
<div class="tn-close" node-type="close" style="display:none;"><a href="javascript:;"><i></i>关闭置顶</a></div>
<div class="tn-person-r" style="float:right;">
<div class="tn-title tn-title-login" id="SI_Top_Login">
<a class="tn-tab" href="javascript:;" suda-uatrack="key=index_new_menu&amp;value=weibo_signin"><i>登录</i>
</a>
<!-- <span style="display:none;" class="tn-tab"> <i id="SI_Top_Login"></i>
                                    </span> -->
<div class="tn-topmenulist tn-topmenulist-b" id="SI_Top_LoginLayer" style="">
</div>
</div>
<div class="tn-title" id="SI_Top_Logout" style="display:none;">
<span class="tn-user"><i>欢迎您，<a href="javascript:;" id="SI_Top_Nick" target="_blank"></a>
<a class="tn-logout" href="javascript:;" id="SI_Top_Logout_a">退出</a></i>
</span>
</div>
<div class="tn-title" id="SI_Top_Weibo">
<a class="tn-tab" href="https://weibo.com/" suda-uatrack="key=index_new_menu&amp;value=weibo_click" target="_blank"> <i>微博
                                            <em class="tn-new" style="display:none;"></em>
<span class="tn-arrow"> </span></i> </a>
</div>
<div class="tn-title" id="SI_Top_Blog">
<a class="tn-tab" href="http://blog.sina.com.cn" suda-uatrack="key=index_new_menu&amp;value=blog_click" target="_blank">
<i>博客
                                            <em class="tn-new" style="display:none;"></em>
<span class="tn-arrow"> </span></i> </a>
</div>
<div class="tn-title" id="SI_Top_Mail">
<a class="tn-tab" href="https://mail.sina.com.cn" suda-uatrack="key=index_new_menu&amp;value=mail_click" target="_blank"> <i>邮箱
                                            <em class="tn-new" style="display:none;"></em>
<span class="tn-
```

*（完整HTML内容已保存，长度: 200777 字符）*

### HTML格式

```html
<article class="news-article">
    <header>
        <h1>“光纤之父”高锟离世 曾获诺贝尔物理学奖</h1>
        <div class="meta">
            <span class="source">国内要闻-新浪新闻</span>
            <time datetime="Sun, 23 Sep 2018 10:47:40 GMT">Sun, 23 Sep 2018 10:47:40 GMT</time>
        </div>
    </header>
    <section class="summary">
        <p>原标题：”光纤之父”高锟离世 享年84岁
　　据香港媒体报道，香港中文大学前校长、有“光纤之父”之称的高锟，今天（9月23日）下午在医院离世，享年84岁。

　　高锟光纤、宽带传送等科技成就极高，在国际学术领域获奖无数，并在2009年10月6日获得诺贝尔物理学奖，以表扬其“....</p>
    </section>
    <section class="content">
                <p>租用小电充电宝已经及时归还却被收费99元。2月14日晚6点30分左右在南京市碑亭巷俺村活鱼使用支付宝租用小电充电宝，并于当晚7点25分左右归还充电宝，正确插入卡槽，充电宝指示灯亮起。 2月19日早上7点30分左右收到支付宝扣款99元消息。</p>
        <p>就算在质保内也不能质保！京东销售方当时购买时并没有给发票及并没告知需要保留外包装！本来不给发票就有逃税嫌疑！要求京东履行质保义务。</p>
        <p>上海天津广东河南四川福建江苏河北湖北湖南陕西黑龙江安徽江西海南山东广西</p>
        <p>Copyright ©1996-2025 SINA Corporation, All Rights Reserved</p>
        <p>隐私保护新浪公司版权所有京ICP证000007</p>
        <p>违法和不良信息举报电话：4001102288　举报邮箱：jubao@vip.sina.com</p>
        <p>京网文﹝2023﹞4325-128号互联网新闻信息服务许可编号：11220180001北京新浪互联信息服务有限公司</p>
        <p>(京)网药械信息备字（2024）第 00220 号　京教研[2002]7号　电信业务审批[2001]字第379号</p>
        <p>增值电信业务经营许可证B1.B2-20090108　增值电信业务经营许可证：京ICP证000007号</p>
        <p>广播电视节目制作经营许可证（京）字第00828号 甲测资字11110398京公网安备11000002000016号</p>
        <p>互联网宗教信息服务许可证：京（2025）0000015</p>
    </section>
    
    <div class="images">
        <img src="https://beacon.sina.com.cn/a.gif?noScript" alt="新闻图片" />
        <img src="https://i0.sinaimg.cn/cha/images/c.gif" alt="新闻图片" />
        <img src="https://n.sinaimg.cn/finance/blackcat/pc/blink.gif" alt="新闻图片" />
        <img src="https://k.sinaimg.cn/n/news/transform/525/w315h210/20251126/3626-42e1925d2279a6600af5b3a25397c0de.jpg/w210h140z1l50t1q100f16de.jpg" alt="新闻图片" />
        <img src="https://k.sinaimg.cn/n/news/transform/525/w315h210/20251126/f301-3de4fdf63a4045ffbd68266341087b3b.jpg/w210h140z1l50t1q100f17e6.jpg" alt="新闻图片" />
        <img src="https://k.sinaimg.cn/n/news/transform/525/w315h210/20251126/3fd0-be0ddc2df1eddbc5a0aa3badc394409f.jpg/w210h140z1l50t1q100f158f.jpg" alt="新闻图片" />
        <img src="https://k.sinaimg.cn/n/front20251126ac/534/w480h854/20251126/265f-64af5de7d7ff2375d5f56000ef4258ea.jpg/w210h180z1l50t1q100f19d5.jpg" alt="新闻图片" />
        <img src="https://k.sinaimg.cn/n/front20251125ac/200/w640h360/20251125/62f6-2efe4ccb1f98d7e748f466eecd736203.jpg/w210h180z1l50t1q100f1f05.jpg" alt="新闻图片" />
        <img src="https://k.sinaimg.cn/n/ent/175/w105h70/20190204/X-Ps-hsmkfyp5293165.jpg/w105h70z1l50t1q100f12c2.jpg" alt="新闻图片" />
        <img src="https://k.sinaimg.cn/n/tech/transform/175/w105h70/20210103/b238-kherpxx2417985.jpg/w105h70z1l50t1q100f1a86.jpg" alt="新闻图片" />
        <img src="https://k.sinaimg.cn/n/default/transform/530/w890h440/20240129/1191-110e246f21e647c45617919d2b80db8f.jpg/w105h70z1l50t1q100f14a0.jpg" alt="新闻图片" />
        <img src="https://www.sinaimg.cn/home/main/blk/d.gif" alt="新闻图片" />
        <img src="https://k.sinaimg.cn/n/sinacn20231226ac/175/w105h70/20231226/7a1a-6664b0e3acb0d43c68077acad1c718ba.jpg/w105h70l50t507a3.jpg" alt="新闻图片" />
        <img src="https://k.sinaimg.cn/n/sinacn20240627ac/175/w105h70/20240627/0734-e904349456efda740429b0d76119b298.jpg/w105h70l50t50922.jpg" alt="新闻图片" />
        <img src="https://k.sinaimg.cn/n/sinacn20231201ac/175/w105h70/20231201/12e8-6207e7783299214a30b5701ec8e13b88.jpg/w105h70l50t50315.jpg" alt="新闻图片" />
        <img src="https://k.sinaimg.cn/n/sinacn20231207ac/175/w105h70/20231207/1ddd-d778afd0f06e40cb4937999df23a1ead.jpg/w105h70l50t50017.jpg" alt="新闻图片" />
        <img src="https://k.sinaimg.cn/n/sinacn20241106ac/175/w105h70/20241106/3d49-a25a5e9f5ae1900f143be962d2ec2a45.jpg/w105h70l50t506d5.jpg" alt="新闻图片" />
        <img src="https://k.sinaimg.cn/n/sinacn20231205ac/175/w105h70/20231205/18a2-2184e78b2d32982da1126c0a51721e35.jpg/w105h70l50t50b95.jpg" alt="新闻图片" />
        <img src="https://k.sinaimg.cn/n/sinacn20231122ac/175/w105h70/20231122/451b-55dfe25be153a493beebd966e516597c.jpg/w105h70l50t501d9.jpg" alt="新闻图片" />
        <img src="https://k.sinaimg.cn/n/sinacn20231201ac/175/w105h70/20231201/46c2-ad26245a4ccc16cd3c1480559f450c77.jpg/w105h70l50t5097f.jpg" alt="新闻图片" />
        <img src="https://k.sinaimg.cn/n/sinacn20231211ac/175/w105h70/20231211/897e-fd911e9729bb8e61937d3ebbce4e9908.jpg/w105h70l50t50c17.jpg" alt="新闻图片" />
        <img src="https://k.sinaimg.cn/auto5/autoimg/brand/03/13/65f108ac30c2d5901303_95.png/w49h49l50t50q80b07.jpg" alt="新闻图片" />
        <img src="https://k.sinaimg.cn/n/auto/transform/brand/190/w95h95/20210722/d75f-567029ba54fe3e07bce37c55fcd1fd1d.jpg/w49h49l50t50q80443.jpg" alt="新闻图片" />
        <img src="https://k.sinaimg.cn/auto2/autoimg/brand/00/00/338_5102_95.png/w49h49l50t50q80b08.jpg" alt="新闻图片" />
        <img src="https://k.sinaimg.cn/auto4/autoimg/brand/12/28/658d28c596f355302812_95.png/w49h49l50t50q80fda.jpg" alt="新闻图片" />
        <img src="https://k.sinaimg.cn/auto/autoimg/brand/09/15/6504042d8bb606401509_95.jpg/w49h49l50t50q801e1.jpg" alt="新闻图片" />
        <img src="https://k.sinaimg.cn/n/auto/transform/brand/320/w160h160/20210722/c51c-3c5c8562431b21b939aa89d263e12190.jpg/w49h49l50t50q801b7.jpg" alt="新闻图片" />
        <img src="https://k.sinaimg.cn/www1/qc/autoimg/brand/00/00/203_7585_106.jpg/w49h49l50t50q8001f.jpg" alt="新闻图片" />
        <img src="https://k.sinaimg.cn/www/qc/autoimg/brand/00/00/206_1418_106.jpg/w49h49l50t50q80f39.jpg" alt="新闻图片" />
        <img src="https://k.sinaimg.cn/n/auto/190/w95h95/20220623/a8e7-559f732ec50db75575461337ab5186ee.jpg/w49h49l50t50q804a6.jpg" alt="新闻图片" />
        <img src="https://k.sinaimg.cn/n/default/transform/191/w95h96/20230130/1e32-52e8c71c291133f3bef0bdacf4aec04f.png/w49h49l50t50q80ef0.jpg" alt="新闻图片" />
        <img src="https://k.sinaimg.cn/auto/autoimg/brand/00/00/225_0926_106.png/w49h49l50t50q80bdc.jpg" alt="新闻图片" />
        <img src="https://k.sinaimg.cn/n/news/379/w218h161/20180516/SwMa-harvfht6299629.png/w654h483z1l50t1q100f1b93.jpg" alt="新闻图片" />
        <img src="https://image.sinajs.cn/newchart/small/t/sh000001.gif" alt="新闻图片" />
        <img src="https://ess.leju.com/house/photo/42-1-4w9weSsp48NYGuEhKBpOrqg9dPlK9PnPct0lZO3y71lYewnOmhBV36IgyZHcQsfhLNoTX85E8mMu68xn_S105X70.jpg" alt="新闻图片" />
        <img src="https://ess.leju.com/esf/photo/38-1-N57JgHJaodwHuqpvZ826ku0IySUdcYsyjrkYOlCIFt7I4DNQf4VGeiF2HDDZXgLp0Vib2byBvcqcsX8q_sk02e31f_S52x35.png" alt="新闻图片" />
        <img src="https://ess.leju.com/house/photo/42-1-wzSzUBTq28ee7al1DOOsc2TQYNX5IZEhpU88sLXjh6cFDwEDyUygHgPiiEfJWeSDkl52CFgiUUabKiBS_S105x70.jpg" alt="新闻图片" />
        <img src="https://k.sinaimg.cn/n/autosina/sinatopic/588/w299h289/20220509/59d1-f66d16681b91bd2c46c67938027d8e5d.jpg/w45h45z1l50t50q80046.jpg" alt="新闻图片" />
        <img src="https://k.sinaimg.cn/n/autosina/sinatopic/299/w119h180/20220909/5edb-685e35fd3f59968554126954f85edbaa.jpg/w45h45z1l50t50q8039b.jpg" alt="新闻图片" />
        <img src="https://k.sinaimg.cn/n/autosina/sinatopic/125/w690h1035/20220509/8b9a-f1715b27c274e849b8b41a79fc5288ca.jpg/w45h45z1l50t50q805ee.jpg" alt="新闻图片" />
        <img src="https://k.sinaimg.cn/n/autosina/sinatopic/315/w180h135/20230816/ae92-e7da2b7c39519f2cb1e22e5aedb9ab6b.jpg/w45h45z1l50t50q8086c.jpg" alt="新闻图片" />
        <img src="https://k.sinaimg.cn/n/autosina/sinatopic/599/w305h294/20220509/0f00-12537e60469fd589e328f3dc850150c0.jpg/w45h45z1l50t50q80294.jpg" alt="新闻图片" />
        <img src="https://k.sinaimg.cn/n/autosina/sinatopic/281/w101h180/20231208/ce07-17da2ba18ecfcf8367c8443706c00eb3.jpg/w45h45z1l50t50q80e40.jpg" alt="新闻图片" />
        <img src="https://i3.sinaimg.cn/dy/deco/2013/0305/d.gif" alt="新闻图片" />
    </div>
    <footer>
        <a href="http://go.rss.sina.com.cn/redirect.php?url=http://news.sina.com.cn/c/2018-09-23/doc-ihkmwytn7252946.shtml" target="_blank">阅读原文</a>
    </footer>
</article>
```

**原文链接：** [http://go.rss.sina.com.cn/redirect.php?url=http://news.sina.com.cn/c/2018-09-23/doc-ihkmwytn7252946.shtml](http://go.rss.sina.com.cn/redirect.php?url=http://news.sina.com.cn/c/2018-09-23/doc-ihkmwytn7252946.shtml)

---

## 3. Show HN: We built an open source, zero webhooks payment processor

**来源：** Hacker News  
**时间：** 2025-11-25T17:33:50  
**分类：** tech  
**语言：** en  

### 摘要

Hi HN! For the past bit we’ve been building Flowglad (<a href="https:&#x2F;&#x2F;flowglad.com">https:&#x2F;&#x2F;flowglad.com</a>) and can now feel it’s just gotten good enough to share with you all:<

### 正文

The easiest way to make internet money.Get Started·Quickstart·Website·Issues·Discord

Infinite pricing models, one source of truth, zero webhooks.

First, install the packages necessary Flowglad packages based on your project setup:

Flowglad integrates seamlessly with your authentication system and requires only a few lines of code to get started in your Next.js app. Setup typically takes under a minute:

Create a utility to generate your Flowglad server instance. Pass your own customer/user/organization IDs—Flowglad never requires its own customer IDs to be managed in your app:

Add an API route so the Flowglad client can communicate securely with your backend:

In your root layout (App Router) or _app (Pages Router):

That’s it—Flowglad will use your app’s internal user IDs for all billing logic and integrate billing status into your frontend in real time.

B2C apps:Useuser.idas the customer ID.B2B apps:Useorganization.idorteam.idas the customer ID.

Flowglad does not require you to change your authentication system or manage Flowglad customer IDs. Just pass your own!

Frontend Example: Checking Feature Access and Usage

Backend Example: Server-side Feature and Usage Checks

First, set up a pricing model. You can do so in thedashboardin just a few clicks using a template, that you can then customize to suit your specific needs.

We currently have templates for the following pricing models:

And more on the way. If you don't see a pricing model from our templates that suits you, you can always make one from scratch.

In the last 15 years, the market has given developers more options than ever for every single part of their stack. But when it comes to payments, there have been virtually zero new entrants. The existing options are slim, and almost all of them require us to talk to sales to even set up an account. When it comes toself-servepayments, there are even fewer options.

The result? The developer experience and cost of payments has barely improved in that time. Best in class DX in payments feels eerily suspended in 2015. Meanwhile, we've enjoyed constant improvements in auth, compute, hosting, and practically everything else.

Flowglad wants to change that.

We're building a payments layer that lets you:

Achieving this mission will take time. It will be hard. It might even make some people unhappy. But with AI bringing more and more developers on line and exploding the complexity of startup billing, the need is more urgent than ever.

### 相关图片

![图片](https://github.com/flowglad/flowglad/raw/main/public/github-image-banner-light-mode.jpg)
![图片](https://camo.githubusercontent.com/986bd25a5172abfa440688cc735e93c82a7e315f2fb5fd8aa77e60cea4382622/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636861742d6f6e253230646973636f72642d3732383944412e737667)
![图片](https://camo.githubusercontent.com/69949d87c2412ad8ba36f9d5424c75a17c0441ebbc1bdaea270dcf41413245c9/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f666f6c6c6f772f666c6f77676c61642e7376673f6c6162656c3d466f6c6c6f7725323040666c6f77676c6164)
![图片](https://camo.githubusercontent.com/a6b8cb5682163e11ecce5a28a5c82b80d0a49645d2d784f7c16d5dc5f466c225/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4261636b6564253230627925323059432d464634303030)
![图片](https://github.com/flowglad/flowglad/raw/main/public/fg-demo.gif)

### HTML原始内容

```html
<body class="logged-out env-production page-responsive" style="word-wrap: break-word;">
<div class="logged-out env-production page-responsive" data-turbo-body="" style="word-wrap: break-word;">
<div class="position-relative header-wrapper js-header-wrapper">
<a class="px-2 py-4 color-bg-accent-emphasis color-fg-on-emphasis show-on-focus js-skip-to-content" data-skip-target-assigned="false" href="#start-of-content">Skip to content</a>
<span class="progress-pjax-loader Progress position-fixed width-full" data-view-component="true">
<span class="Progress-item progress-pjax-loader-bar left-0 top-0 color-bg-accent-emphasis" data-view-component="true" style="width: 0%;"></span>
</span>
<link crossorigin="anonymous" href="https://github.githubassets.com/assets/primer-react.c918010dadb8d146d90b.module.css" media="all" rel="stylesheet"/>
<link crossorigin="anonymous" href="https://github.githubassets.com/assets/keyboard-shortcuts-dialog.29aaeaafa90f007c6f61.module.css" media="all" rel="stylesheet"/>
<react-partial data-attempted-ssr="false" data-react-profiling="false" data-ssr="false" partial-name="keyboard-shortcuts-dialog">

<div data-target="react-partial.reactRoot"></div>
</react-partial>




<div class="js-stale-session-flash stale-session-flash flash flash-warn flash-full" data-view-component="true" hidden="hidden">
<svg aria-hidden="true" class="octicon octicon-alert" data-view-component="true" height="16" version="1.1" viewbox="0 0 16 16" width="16">
<path d="M6.457 1.047c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0 1 14.082 15H1.918a1.75 1.75 0 0 1-1.543-2.575Zm1.763.707a.25.25 0 0 0-.44 0L1.698 13.132a.25.25 0 0 0 .22.368h12.164a.25.25 0 0 0 .22-.368Zm.53 3.996v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0ZM9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z"></path>
</svg>
<span class="js-stale-session-flash-signed-in" hidden="">You signed in with another tab or window. <a class="Link--inTextBlock" href="">Reload</a> to refresh your session.</span>
<span class="js-stale-session-flash-signed-out" hidden="">You signed out in another tab or window. <a class="Link--inTextBlock" href="">Reload</a> to refresh your session.</span>
<span class="js-stale-session-flash-switched" hidden="">You switched accounts on another tab or window. <a class="Link--inTextBlock" href="">Reload</a> to refresh your session.</span>
<button aria-labelledby="tooltip-40246932-a40a-457a-b384-4b5546968d3b" class="Button Button--iconOnly Button--invisible Button--medium flash-close js-flash-close" data-view-component="true" id="icon-button-a7885ad3-d7ec-4f2b-b95d-a9b47e22da1e" type="button"> <svg aria-hidden="true" class="octicon octicon-x Button-visual" data-view-component="true" height="16" version="1.1" viewbox="0 0 16 16" width="16">
<path d="M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z"></path>
</svg>
</button><tool-tip class="sr-only position-absolute" data-direction="s" data-type="label" data-view-component="true" for="icon-button-a7885ad3-d7ec-4f2b-b95d-a9b47e22da1e" id="tooltip-40246932-a40a-457a-b384-4b5546968d3b" popover="manual">Dismiss alert</tool-tip>
</div>
</div>
<div class="show-on-focus" id="start-of-content"></div>
<div class="flash-container" data-turbo-replace="" id="js-flash-container">
<template class="js-flash-template">
<div class="flash flash-full {{ className }}">
<div>
<button aria-label="Dismiss this message" autofocus="" class="flash-close js-flash-close" type="button">
<svg aria-hidden="true" class="octicon octicon-x" data-view-component="true" height="16" version="1.1" viewbox="0 0 16 16" width="16">
<path d="M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z"></path>
</svg>
</button>
<div aria-atomic="true" class="js-flash-alert" role="alert">
<div>{{ message }}</div>
</div>
</div>
</div>
</template>
</div>
<div class="application-main" data-commit-hovercards-enabled="" data-discussion-hovercards-enabled="" data-issue-and-pr-hovercards-enabled="" data-project-hovercards-enabled="">
<div class="" itemscope="" itemtype="http://schema.org/SoftwareSourceCode">
<main id="js-repo-pjax-container">
<div class="pt-3 hide-full-screen" data-turbo-replace="" id="repository-container-header" style="background-color: var(--page-header-bgColor, var(--color-page-header-bg));">
<div class="d-flex flex-nowrap flex-justify-end mb-3 px-3 px-lg-5" style="gap: 1rem;">
<div class="flex-auto min-width-0 width-fit">
<div class="d-flex flex-wrap flex-items-center wb-break-word f3 text-normal">
<svg aria-hidden="true" class="octicon octicon-repo color-fg-muted mr-2" data-view-component="true" height=
```

*（完整HTML内容已保存，长度: 160713 字符）*

### HTML格式

```html
<article class="news-article">
    <header>
        <h1>Show HN: We built an open source, zero webhooks payment processor</h1>
        <div class="meta">
            <span class="source">Hacker News</span>
            <time datetime="2025-11-25T17:33:50">2025-11-25T17:33:50</time>
        </div>
    </header>
    <section class="summary">
        <p>Hi HN! For the past bit we’ve been building Flowglad (&lt;a href=&quot;https:&amp;#x2F;&amp;#x2F;flowglad.com&quot;&gt;https:&amp;#x2F;&amp;#x2F;flowglad.com&lt;/a&gt;) and can now feel it’s just gotten good enough to share with you all:&lt;</p>
    </section>
    <section class="content">
                <p>The easiest way to make internet money.Get Started·Quickstart·Website·Issues·Discord</p>
        <p>Infinite pricing models, one source of truth, zero webhooks.</p>
        <p>First, install the packages necessary Flowglad packages based on your project setup:</p>
        <p>Flowglad integrates seamlessly with your authentication system and requires only a few lines of code to get started in your Next.js app. Setup typically takes under a minute:</p>
        <p>Create a utility to generate your Flowglad server instance. Pass your own customer/user/organization IDs—Flowglad never requires its own customer IDs to be managed in your app:</p>
        <p>Add an API route so the Flowglad client can communicate securely with your backend:</p>
        <p>In your root layout (App Router) or _app (Pages Router):</p>
        <p>That’s it—Flowglad will use your app’s internal user IDs for all billing logic and integrate billing status into your frontend in real time.</p>
        <p>B2C apps:Useuser.idas the customer ID.B2B apps:Useorganization.idorteam.idas the customer ID.</p>
        <p>Flowglad does not require you to change your authentication system or manage Flowglad customer IDs. Just pass your own!</p>
        <p>Frontend Example: Checking Feature Access and Usage</p>
        <p>Backend Example: Server-side Feature and Usage Checks</p>
        <p>First, set up a pricing model. You can do so in thedashboardin just a few clicks using a template, that you can then customize to suit your specific needs.</p>
        <p>We currently have templates for the following pricing models:</p>
        <p>And more on the way. If you don&#39;t see a pricing model from our templates that suits you, you can always make one from scratch.</p>
        <p>In the last 15 years, the market has given developers more options than ever for every single part of their stack. But when it comes to payments, there have been virtually zero new entrants. The existing options are slim, and almost all of them require us to talk to sales to even set up an account. When it comes toself-servepayments, there are even fewer options.</p>
        <p>The result? The developer experience and cost of payments has barely improved in that time. Best in class DX in payments feels eerily suspended in 2015. Meanwhile, we&#39;ve enjoyed constant improvements in auth, compute, hosting, and practically everything else.</p>
        <p>Flowglad wants to change that.</p>
        <p>We&#39;re building a payments layer that lets you:</p>
        <p>Achieving this mission will take time. It will be hard. It might even make some people unhappy. But with AI bringing more and more developers on line and exploding the complexity of startup billing, the need is more urgent than ever.</p>
    </section>
    
    <div class="images">
        <img src="https://github.com/flowglad/flowglad/raw/main/public/github-image-banner-light-mode.jpg" alt="新闻图片" />
        <img src="https://camo.githubusercontent.com/986bd25a5172abfa440688cc735e93c82a7e315f2fb5fd8aa77e60cea4382622/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636861742d6f6e253230646973636f72642d3732383944412e737667" alt="新闻图片" />
        <img src="https://camo.githubusercontent.com/69949d87c2412ad8ba36f9d5424c75a17c0441ebbc1bdaea270dcf41413245c9/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f666f6c6c6f772f666c6f77676c61642e7376673f6c6162656c3d466f6c6c6f7725323040666c6f77676c6164" alt="新闻图片" />
        <img src="https://camo.githubusercontent.com/a6b8cb5682163e11ecce5a28a5c82b80d0a49645d2d784f7c16d5dc5f466c225/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4261636b6564253230627925323059432d464634303030" alt="新闻图片" />
        <img src="https://github.com/flowglad/flowglad/raw/main/public/fg-demo.gif" alt="新闻图片" />
    </div>
    <footer>
        <a href="https://github.com/flowglad/flowglad" target="_blank">阅读原文</a>
    </footer>
</article>
```

**原文链接：** [https://github.com/flowglad/flowglad](https://github.com/flowglad/flowglad)

---

## 4. Launch HN: Onyx (YC W24) – Open-source chat UI

**来源：** Hacker News  
**时间：** 2025-11-25T14:20:30  
**分类：** tech  
**语言：** en  

### 摘要

Hey HN, Chris and Yuhong here from Onyx (<a href="https:&#x2F;&#x2F;github.com&#x2F;onyx-dot-app&#x2F;onyx" rel="nofollow">https:&#x2F;&#x2F;github.com&#x2F;onyx-dot-app&#x2F;onyx</a>). We’re building

### 正文

Demo:https://youtu.be/2g4BxTZ9ztg

Two years ago, Yuhong and I had the same recurring problem. We were on growing teams and it was ridiculously difficult to find the right information across our docs, Slack, meeting notes, etc. Existing solutions required sending out our company's data, lacked customization, and frankly didn't work well. So, we started Danswer, an open-source enterprise search project built to be self-hosted and easily customized.

As the project grew, we started seeing an interesting trend—even though we were explicitly a search app, people wanted to use Danswer just to chat with LLMs. We’d hear, “the connectors, indexing, and search are great, but I’m going to start by connecting GPT-4o, Claude Sonnet 4, and Qwen to provide my team with a secure way to use them”.

Many users would add RAG, agents, and custom tools later, but much of the usage stayed ‘basic chat’. We thought: “why would people co-opt an enterprise search when other AI chat solutions exist?”

As we continued talking to users, we realized two key points:

(1) just giving a company secure access to an LLM with a great UI and simple tools is a huge part of the value add of AI

(2) providing thiswellis much harder than you might think and the bar is incredibly high

Consumer products like ChatGPT and Claude already provide a great experience—and chat with AI for work is something (ideally) everyone at the company uses 10+ times per day. People expect the same snappy, simple, and intuitive UX with a full feature set. Getting hundreds of small details right to take the experience from “this works” to “this feels magical” is not easy, and nothing else in the space has managed to do it.

So ~3 months ago we pivoted to Onyx, the open-source chat UI with:

- (truly) world class chat UX. Usable both by a fresh college grad who grew up with AI and an industry veteran who’s using AI tools for the first time.

- Support for all the common add-ons: RAG, connectors, web search, custom tools, MCP, assistants, deep research.

- RBAC, SSO, permission syncing, easy on-prem hosting to make it work for larger enterprises.

Through building features like deep research and code interpreter that work across model providers, we've learned a ton of non-obvious things about engineering LLMs that have been key to making Onyx work. I'd like to share two that were particularly interesting (happy to discuss more in the comments).

First, context management is one of the most difficult and important things to get right. We’ve found that LLMs really struggle to remember both system prompts and previous user messages in long conversations. Even simple instructions like “ignore sources of type X” in the system prompt are very often ignored. This is exacerbated by multiple tool calls, which can often feed in huge amounts of context. We solved this problem with a “Reminder” prompt—a short 1-3 sentence blurb injected at the end of the user message that describes the non-negotiables that the LLM must abide by. Empirically, LLMs attend most to the very end of the context window, so this placement gives the highest likelihood of adherence.

Second, we’ve needed to build an understanding of the “natural tendencies” of certain models when using tools, and build around them. For example, the GPT family of models are fine-tuned to use a python code interpreter that operates in a Jupyter notebook. Even if told explicitly, it refuses to add `print()` around the last line, since, in Jupyter, this last line is automatically written to stdout. Other models don’t have this strong preference, so we’ve had to design our model-agnostic code interpreter to also automatically `print()` the last bare line.

So far, we’ve had a Fortune 100 team fork Onyx and provide 10k+ employees access to every model within a single interface, and create thousands of use-case specific Assistants for every department, each using the best model for the job. We’ve seen teams operating in sensitive industries completely airgap Onyx w/ locally hosted LLMs to provide a copilot that wouldn’t have been possible otherwise.

If you’d like to try Onyx out, followhttps://docs.onyx.app/deployment/getting_started/quickstartto get set up locally w/ Docker in <15 minutes. For our Cloud:https://www.onyx.app/. If there’s anything you'd like to see to make it a no-brainer to replace your ChatGPT Enterprise/Claude Enterprise subscription, we’d love to hear it!

Also, open-source works really here, since connectors are a long-tail game. We've tried to make it easy to add connectors (a single python interface), and as a result over half of our connectors are contributed by the community. We expect that percentage to grow over time. This means that compared to something like Agentspace, we'll very likely be connected to all of the key tools at your company (and if we aren't, you can easily add an integration).

The main thing Ireallycare about is voice mode, as that's my far preferred way of interacting with LLMs for longer backs and forths (most apps I've seen disable a lot of other functionality during it, which I hate, btw).

Two other things I would like to see are canvas mode and scheduled actions (withdecision making capability - e.g. "send a notification if X happens").

I assume such features are going to continue being invented, so I find extensibility to be ahugedeal. So much so that one thing I could imagine going really well would be a UI on top of Langchain, which already has most of the facilities for that!

My main gripe with openwebui, in addition to it being slow is the fact that it mangles documents in the OCR step. tables that could have been understood great by an multi modal llm, just gets mangled by the ocr and lost instead of storing both a text and original representation.

Being able to properly searcbin the knowlege base lime the llm does, but manually would be nice (like get recommendations for docs to add).

My usecase is mostly writing, so having a integrated document refinery editor is also a nice feature list.

I'm probably rambling but these are my base use-cases for a llm ui I personally have found.

Writing is a really common use case, and something we'd like to explore more. Currently people often use Onyx for "write something combining X, Y, and Z documents", but I feel that's just scratching the surface.

But stoked to get alternatives to the area, will try it out once i get time soon.

It’s nice to see an attempt at an end to end stack (for all that it seems this is “obvious” … there are not that many functional options) but wow we’ve forgotten the basis of making useful products. I’m hoping it gets enough time to bake.

The admin side of the house has been missing a bit of love, and we have a large overhaul coming soon that I'm hoping addresses some (most?) of your concerns. For now, if you'd like to view documents that have been processed, you can check out the `Explorer` panel on the left.

In general, I'd love to hear more about what gives it that "unbaked" feel for you if you're up for a quick chat.

Something like this could have a nice future as an open source chat framework for building custom UIs if it's well made and modular, but that isn't gonna work well with a SaaS model.

"What's Max's GitHub username?"
"I need wire transfer instructions for an incoming wire"

We also index competitors' helpdesks and KB articles to track new features they're rolling out.
Our tech support team uses it daily because Freshdesk's AI is terrible and their internal KB search is lackluster. Onyx actually finds things.
The value isn't in being "one chat to rule them all" — it's in unified search across disparate systems with citations. That's not getting commoditized anytime soon.
Keep up the good work, team.

It does requires having UI components for many different types of interactions (e.g. many ways to collect user input mid-session + display different tools responses like graphs and interactives). With this, people should be able to easily build complex tools/flows on top of that UI, and get a nice, single interface (no siloed tools/swapping) for free. And having this UI be open-source make this easier.

And this is all made all the more important when supporting the wide range of models, even "weaker" open-source models.

Can you call it open source if you need a subscription license to run / edit the code?

- UI-based white labeling

Content under backend/ee requires a license, everything else is MIT Expat.
Pretty standard stuff.

> Can you call it open source if you need a subscription license to run / edit the code?

MIT is open source, their other stuff isn't. Pretty clear.

Could you elaborate why this approach is confusing?

A common "trick" for commercial open source software is to use a copyleft license, which restricts redistribution as part of commercial products, and to offer a paid license to get around that.

[1]:https://opensource.org/osd

I was responding to parent's question though: "Can you call it open source if you need a subscription license to run / edit the code?"

I'd say no. If you have the code in front of you, it shouldn't require a license to run. Even if the whole point of the open source software is to interact with a proprietary piece of software or service, you could still run it for free, it probably just wouldn't have much utility.

> Many people believe that the spirit of the GNU Project is that you should not charge money for distributing copies of software, or that you should charge as little as possible—just enough to cover the cost. This is a misunderstanding.

> Actually, we encourage people who redistribute free software to charge as much as they wish or can. If a license does not permit users to make copies and sell them, it is a nonfree license.

https://www.gnu.org/philosophy/selling.html

And even if the source code was only distributed to paying customers, that'd likely be a temporary situation. A relevant quote:

"With free software, users don't have to pay the distribution fee in order to use the software. They can copy the program from a friend who has a copy, or with the help of a friend who has network access."

I do read the GPLv3 such that if someone _does_ buy the code in any fashion, you must provide the source code to them for free. Relevant excerpt from section 6:

"[...] give anyone who possesses the object code either (1) a copy of the Corresponding Source for all the software in the product that is covered by this License, on a durable physical medium customarily used for software interchange, for a price no more than your reasonable cost of physically performing this conveying of source, or (2) access to copy the Corresponding Source from a network server at no charge."

But yeah, no obligation to provide the source code for free to non-customers, fair point. Just no ability to stop customers from sharing it with non-customers. Does make sense.

One of our largest users has forked the repo and has 20+ commits back to the repo of small customizations that are important for them (and that they could never get with ChatGPT Enterprise).

Lots of companies we talk to value having the best model for the job (e.g. not being tied to ONLY OpenAI models for example).

Compared to model provider offerings, we also (thanks to open-source contributions) cover many more existing apps when it comes to connectors.

Onyx Devs:  This looks awesome, I will definitely add it to my list of things to try out... close to the top!  Thanks, and please keep it cool!

- Instability when self-hosting

- Hard to get in touch with sales when looking for SLA-based contracts

- Cluttered product; Multiple concepts seemingly serving the same purpose (e.g. function calling vs. MCP); Most pre-MCP tools suffer from this

- Trouble integrating it with OIDC

- Bad docs that are mostly LLM generated

Both internal RAG and web search are hard to do well, and since we've started as an enterprise search project we've spent a lot of time making it good.

Most (all?) of these projects have UXs that are quite complicated (e.g. exposing front-and-center every model param like Top P without any explanation, no clear distinction between admin/regular user features, etc.). For broader deployments this can overwhelm people who are new to AI tools.

Finally trying to do anything beyond a simple back and forth with a single tool calls isn't great with a lot of these projects. So something like "find me all the open source chat options, understand their strengths/weaknesses, and compile that into a spreadsheet" will work well with Onyx, but not so well with other options (again partially due to our enterprise search roots).

a mobile application that has parity on the same features that ChatGPT and Claude does...

Things like shortcuts to access the chat + ability to reach into the local file system are very compelling.

> but I’m going to start by connecting GPT-4o, Claude Sonnet 4, and Qwen to provide my team with a secure way to use them

I did get a little giggle out of that because I've never heard anyone say that hooking up 3rd party llms to anything was any way secure.

The key point there is that many would do it through Azure / Bedrock + locally host the open-source models. Also, all chats / indexed data lives on-prem, and there are better guarantees around retention when using the APIs directly.

I was told there would be rapid prototyping with AI. Haven't seen any of the above.

Curious, it's a crowded space with other enterprise search companies like Glean and Elastic, and other companies coming in like Notion and Slack.

Why should a prospect choose Onyx over the others?

- "pure chat" experience. From our community (and personal use), we've observed that most queries don't actually involve enterprise search. They much more likely to just require the LLMs internal knowledge (or web search / code execution). Compared to all the companies you've mentioned, we've spent a lot more time refining this more common flow.

- Larger connector suite. As soon as one key source isn't connected, the trustworthiness of the system is dramatically decreased. You second guess "is the info needed to answer this question in there?" for every question. We have a community who builds out connectors for themselves, and then contribute it back for everyone to use. This allows us to cover the long-tail better than companies like Notion and Slack.

- Customizability. An open-source application is the perfect middle ground between a SaaS offering and building blocks. A SaaS option doesn't allow for any customization (we have many customers who have contributed back ux enhancements, small features like guardrails, or enhanced configurations that their users want). Building blocks demand too much domain expertise (search, frontend/UX, ...) for it to be realistic for companies to build something great.

In our opinion, it's a bit silly to build completely in house when you can take something like Onyx as the starting point and be >95% of the way there + have a tons of bells and whistles built in.

However it doesn't seem to have MinerU as a supported backend, which is hands-down the best PDF extraction tool I've ever used (and is self-hostable on a machine with a modest GPU). Could it be added?

https://github.com/opendatalab/MinerU

Might have to try this out. OWUI's lagging docs has made managing my own self hosted instance a pain.

PS: Your _See All Connectors_ button on the homepage is 404ing.

"Agents" is a particular area where we feel like we're better than the alternatives (especially if you want something that effectively calls multiple tools in sequence). Curious to hear your thoughts after trying it out!

1/ large connector suite + good RAG. Answers at scale is hard, and from our enterprise search roots, we've spent a lot of time with it. It's something that many teams expect from their chat UI.

2/ deep research + open-source code interpreter.

3/ simpler UX. LibreChat has a lot of customizability exposed front and center to the user, which is great for the power user but can be overwhelming for someone new to using AI systems.

Can you clarify the license and if this actually meets the definition of Open Source as outlined by the OSI [1] or if this is actually just source available similar to OpenWebUI?

Specifically can / does this run without the /onyx/backend/ee and web/src/app/ee directories which are licensed under a proprietary license?

1 -https://opensource.org/licenses

We havehttps://github.com/onyx-dot-app/onyx-foss, for a fully MIT licensed version of the repo if you want to be safe about the license/feel freedom to modify every file.

We are building a competing open source tool[0] with a very similar focus (strongly relying on interoperable standards like MCP; built for enterprise needs, etc.), though bootstrapping with customers rather than being VC funded. It's nice to see a competitor in the field following similar "OSS Friends" principles, while many of the other ones seem to have strong proprietary tendencies.

(Small heads up: The "view all integrations" button goes to a 404)

[0]https://erato.chat/

Why do we have to yet again poorly copy an oversimplified UI?

The value of local models comes from their huge amount of settings/control that they offer. Why must we throw that all away?

Yet again, the world waits for good UI/UX for pro/prosumers with AI systems. No one is learning from ComfyUI, Automatic1111, or SillyTavern. No, LM-Studio is not actually prosumer

For now, the main reasons for a prosumer to use over oobabooga/sillytavern are around the base tool set we provide and the "agent loop". If you ever want to use your single chat interface to do data analysis (code interpreter), multi-step realtime research (deep research), or RAG over large scale data (hybrid search), Onyx would be a particularly good choice.

The target customers are enterprises where 70% of the target users have never used an AI system before and have to go through a AI training before being allowed access to the system.

And no one bothered to say anything to them?

I also wouldn't pin it as chat app specific. Quite a few VC funded open core software has adopted that pattern post ~2020(?): cal.com, Dagster, Gitlab

Thanks, lawyers, you make everything better!

As long as you have Pricing on your website your product is not open source in the true spirit of open sourceness. It is open code for sure but it is a business and so incentive is to run it like a business which will conflate with how the project is used by the community.

Btw, there is nothing wrong with that but let's be honest here if you get this funded (perhaps it already is) who are you going to align your mission with - the open source community or shareholders? I don't think you can do both. Especially if a strong competitor comes along that simply deploys the same version of the product. We have seen this story many times before.

Now, this is completely different from let's say Onyx being an enterprise search product where you create a community-driven version. You might say that fundamentally it is the same code but the way it is presented is different. Nobody will think this is open-source but more of "the source is available" if you want to check.

I thought perhaps it will benefit to share this prospective here if it helps at all.

Btw, I hear good things about Onyx and I have heard that some enterprises are already using it - the open-source version.

I think there can be other valid perspectives than your own.

It's an MIT license. That IS open source.

If they have a commercial strategy - that's a GoodThing. It means they have a viable strategy for staying in business, and keeping the project maintained.

MIT == OpenSource. Pricing == Sustainable. That's a horse worth backing IMO.

At the top level looks like open source but it is not really because parts (the most useful ones) of the project are not. Imagine if python was open source but the core libraries where not. You wont call this open source in the true spirit of open source. You could make the argument that at least it is sustainable because they a have now a business model. It doesn't add up.

I prefer more of a honest take on software. There is nothing wrong to make money while contributing back to the community in some meaningful way or by simply being transparent. In fact this is the best kind and there are plenty of good examples.

All I am saying is that when I see such projects I tend to think that in most cases they are dishonest to themselves or their communities or both.

The source is available and you can do much with it, but the incentive is that this alone should not be enough.

For most people, the chat is the entrypoint to LLMs, and people are growing to expect more and more. So now it might be basic chat, web search, internal RAG, deep research, etc. Very soon, it will be more complex flows kicked off via this interface (e.g. cleaning up a Linear project). The same "chat UI" that is used for basic chat must (imo) support these flows to stay competitive.

On the engineering side, things like Deep Research are quite complex/open-ended, and there can be huge differences in quality between implementations (e.g. ChatGPTs vs Claude). Code interpreter as well (to do it securely) is quite a tricky task.

That being said, I think there is an opportunity for them to discover and serve an important enterprise use case as AI in enterprise hits exponential growth.

On another axis, if you are able to offer BYOK deployments and the customers have huge staff with low usage, it's pretty easy to compete with the big players due to their high per-seat pricing.

The common trend we've seen is that most of these other projects are okay for a true "just send messages to an AI and get responses" use case, but for most things beyond that they fall short / there a lot of paper cuts.

For an individual, this might show up when they try more complex tasks that require multiple tool calls in sequence or when they have a research task to accomplish. For an org, this might show up when trying to manage access to assistants / tools / connected sources.

Our goal is to make sure Onyx is the most advanced and mature option out there. Ithinkwe've accomplished that, so if there's anything missing I'd love to hear about it.

I have used vercel for several projects and I'm not tied to it, but would like to understand how onyx is comparable.

Benefits for my use cases for using vercel have been ease of installation, streaming support, model agnosticity, chat persistence and blob support. I definitely don't like the vendor lock in, though.

we have all of those!

> how onyx is comparable

For an AI-powered research assistant, Onyx might just work out of the box. We have ~45 connectors to common apps (https://github.com/onyx-dot-app/onyx/blob/main/backend/onyx/...), integrations with the most popular web search providers (https://github.com/onyx-dot-app/onyx/blob/main/backend/onyx/...), and a built in tool calling loop w/ deep research support (https://github.com/onyx-dot-app/onyx/blob/main/backend/onyx/...). If you wanted to customize, you could pretty easily tweak this / add additional tools (or even rip this out completely and build your own agent loop).

I could just have kept this "negative" thought to myself, but maybe other lurkers think the same. Something for you guys to have in mind. Good luck!

How we think about it: the chat product should be completely open-source and free (forever). To that end we've moved features like SSO (that used to be "enterprise") to be MIT licensed. The chat interface is something pretty much every team needs (be it a proprietary or open-source solution). You can think of this like Apache Spark for Databricks or Ray for Anyscale.

Also, as other folks have pointed out in the thread, there are quite a few other open source options out there. So there's a a ton of outside pressure for our open-source only offering to be very competitive. We hope this reduces the "enshitification" risk that you speak of.

### HTML原始内容

```html
<body><center><table bgcolor="#f6f6ef" border="0" cellpadding="0" cellspacing="0" id="hnmain" width="85%"><tr><td bgcolor="#ff6600"><table border="0" cellpadding="0" cellspacing="0" style="padding:2px" width="100%"><tr><td style="width:18px;padding-right:4px"><a href="https://news.ycombinator.com"><img height="18" src="y18.svg" style="border:1px white solid; display:block" width="18"/></a></td><td style="line-height:12pt; height:10px;"><span class="pagetop"><b class="hnname"><a href="news">Hacker News</a></b><a href="newest">new</a> | <a href="front">past</a> | <a href="newcomments">comments</a> | <a href="ask">ask</a> | <a href="show">show</a> | <a href="jobs">jobs</a> | <a href="submit" rel="nofollow">submit</a></span></td><td style="text-align:right;padding-right:4px;"><span class="pagetop"><a href="login?goto=item%3Fid%3D46045987">login</a></span></td></tr></table></td></tr><tr style="height:10px"></tr><tr id="bigbox"><td><table border="0" class="fatitem"><tr class="athing submission" id="46045987"><td align="right" class="title" valign="top"><span class="rank"></span></td><td class="votelinks" valign="top"><center><a href="vote?id=46045987&amp;how=up&amp;goto=item%3Fid%3D46045987" id="up_46045987"><div class="votearrow" title="upvote"></div></a></center></td><td class="title"><span class="titleline"><a href="item?id=46045987">Launch HN: Onyx (YC W24) – Open-source chat UI</a></span></td></tr><tr><td colspan="2"></td><td class="subtext"><span class="subline"><span class="score" id="score_46045987">166 points</span> by <a class="hnuser" href="user?id=Weves">Weves</a> <span class="age" title="2025-11-25T14:20:30 1764080430"><a href="item?id=46045987">11 hours ago</a></span> <span id="unv_46045987"></span> | <a href="hide?id=46045987&amp;goto=item%3Fid%3D46045987">hide</a> | <a class="hnpast" href="https://hn.algolia.com/?query=Launch%20HN%3A%20Onyx%20%28YC%20W24%29%20%E2%80%93%20Open-source%20chat%20UI&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="fave?id=46045987&amp;auth=7fe69025f37d79eca3afc02c147781d242fc6214">favorite</a> | <a href="item?id=46045987">118 comments</a></span></td></tr><tr><td colspan="2"></td><td><div class="toptext" style="margin-top:4px">Hey HN, Chris and Yuhong here from Onyx (<a href="https://github.com/onyx-dot-app/onyx" rel="nofollow">https://github.com/onyx-dot-app/onyx</a>). We’re building an open-source chat that works with any LLM (proprietary + open weight) <i>and</i> gives these LLMs the tools they need to be useful (RAG, web search, MCP, deep research, memory, etc.).<p>Demo: <a href="https://youtu.be/2g4BxTZ9ztg" rel="nofollow">https://youtu.be/2g4BxTZ9ztg</a></p><p>Two years ago, Yuhong and I had the same recurring problem. We were on growing teams and it was ridiculously difficult to find the right information across our docs, Slack, meeting notes, etc. Existing solutions required sending out our company's data, lacked customization, and frankly didn't work well. So, we started Danswer, an open-source enterprise search project built to be self-hosted and easily customized.</p><p>As the project grew, we started seeing an interesting trend—even though we were explicitly a search app, people wanted to use Danswer just to chat with LLMs. We’d hear, “the connectors, indexing, and search are great, but I’m going to start by connecting GPT-4o, Claude Sonnet 4, and Qwen to provide my team with a secure way to use them”.</p><p>Many users would add RAG, agents, and custom tools later, but much of the usage stayed ‘basic chat’. We thought: “why would people co-opt an enterprise search when other AI chat solutions exist?”</p><p>As we continued talking to users, we realized two key points:</p><p>(1) just giving a company secure access to an LLM with a great UI and simple tools is a huge part of the value add of AI</p><p>(2) providing this <i>well</i> is much harder than you might think and the bar is incredibly high</p><p>Consumer products like ChatGPT and Claude already provide a great experience—and chat with AI for work is something (ideally) everyone at the company uses 10+ times per day. People expect the same snappy, simple, and intuitive UX with a full feature set. Getting hundreds of small details right to take the experience from “this works” to “this feels magical” is not easy, and nothing else in the space has managed to do it.</p><p>So ~3 months ago we pivoted to Onyx, the open-source chat UI with:</p><p>- (truly) world class chat UX. Usable both by a fresh college grad who grew up with AI and an industry veteran who’s using AI tools for the first time.</p><p>- Support for all the common add-ons: RAG, connectors, web search, custom tools, MCP, assistants, deep research.</p><p>- RBAC, SSO, permission syncing, easy on-prem hosting to make it work for larger enterprises.</p><p>Through building features like deep research and code interpreter that work across model providers, we've learned a ton of non-obvious 
```

*（完整HTML内容已保存，长度: 185165 字符）*

### HTML格式

```html
<article class="news-article">
    <header>
        <h1>Launch HN: Onyx (YC W24) – Open-source chat UI</h1>
        <div class="meta">
            <span class="source">Hacker News</span>
            <time datetime="2025-11-25T14:20:30">2025-11-25T14:20:30</time>
        </div>
    </header>
    <section class="summary">
        <p>Hey HN, Chris and Yuhong here from Onyx (&lt;a href=&quot;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;onyx-dot-app&amp;#x2F;onyx&quot; rel=&quot;nofollow&quot;&gt;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;onyx-dot-app&amp;#x2F;onyx&lt;/a&gt;). We’re building</p>
    </section>
    <section class="content">
                <p>Demo:https://youtu.be/2g4BxTZ9ztg</p>
        <p>Two years ago, Yuhong and I had the same recurring problem. We were on growing teams and it was ridiculously difficult to find the right information across our docs, Slack, meeting notes, etc. Existing solutions required sending out our company&#39;s data, lacked customization, and frankly didn&#39;t work well. So, we started Danswer, an open-source enterprise search project built to be self-hosted and easily customized.</p>
        <p>As the project grew, we started seeing an interesting trend—even though we were explicitly a search app, people wanted to use Danswer just to chat with LLMs. We’d hear, “the connectors, indexing, and search are great, but I’m going to start by connecting GPT-4o, Claude Sonnet 4, and Qwen to provide my team with a secure way to use them”.</p>
        <p>Many users would add RAG, agents, and custom tools later, but much of the usage stayed ‘basic chat’. We thought: “why would people co-opt an enterprise search when other AI chat solutions exist?”</p>
        <p>As we continued talking to users, we realized two key points:</p>
        <p>(1) just giving a company secure access to an LLM with a great UI and simple tools is a huge part of the value add of AI</p>
        <p>(2) providing thiswellis much harder than you might think and the bar is incredibly high</p>
        <p>Consumer products like ChatGPT and Claude already provide a great experience—and chat with AI for work is something (ideally) everyone at the company uses 10+ times per day. People expect the same snappy, simple, and intuitive UX with a full feature set. Getting hundreds of small details right to take the experience from “this works” to “this feels magical” is not easy, and nothing else in the space has managed to do it.</p>
        <p>So ~3 months ago we pivoted to Onyx, the open-source chat UI with:</p>
        <p>- (truly) world class chat UX. Usable both by a fresh college grad who grew up with AI and an industry veteran who’s using AI tools for the first time.</p>
        <p>- Support for all the common add-ons: RAG, connectors, web search, custom tools, MCP, assistants, deep research.</p>
        <p>- RBAC, SSO, permission syncing, easy on-prem hosting to make it work for larger enterprises.</p>
        <p>Through building features like deep research and code interpreter that work across model providers, we&#39;ve learned a ton of non-obvious things about engineering LLMs that have been key to making Onyx work. I&#39;d like to share two that were particularly interesting (happy to discuss more in the comments).</p>
        <p>First, context management is one of the most difficult and important things to get right. We’ve found that LLMs really struggle to remember both system prompts and previous user messages in long conversations. Even simple instructions like “ignore sources of type X” in the system prompt are very often ignored. This is exacerbated by multiple tool calls, which can often feed in huge amounts of context. We solved this problem with a “Reminder” prompt—a short 1-3 sentence blurb injected at the end of the user message that describes the non-negotiables that the LLM must abide by. Empirically, LLMs attend most to the very end of the context window, so this placement gives the highest likelihood of adherence.</p>
        <p>Second, we’ve needed to build an understanding of the “natural tendencies” of certain models when using tools, and build around them. For example, the GPT family of models are fine-tuned to use a python code interpreter that operates in a Jupyter notebook. Even if told explicitly, it refuses to add `print()` around the last line, since, in Jupyter, this last line is automatically written to stdout. Other models don’t have this strong preference, so we’ve had to design our model-agnostic code interpreter to also automatically `print()` the last bare line.</p>
        <p>So far, we’ve had a Fortune 100 team fork Onyx and provide 10k+ employees access to every model within a single interface, and create thousands of use-case specific Assistants for every department, each using the best model for the job. We’ve seen teams operating in sensitive industries completely airgap Onyx w/ locally hosted LLMs to provide a copilot that wouldn’t have been possible otherwise.</p>
        <p>If you’d like to try Onyx out, followhttps://docs.onyx.app/deployment/getting_started/quickstartto get set up locally w/ Docker in &lt;15 minutes. For our Cloud:https://www.onyx.app/. If there’s anything you&#39;d like to see to make it a no-brainer to replace your ChatGPT Enterprise/Claude Enterprise subscription, we’d love to hear it!</p>
        <p>Also, open-source works really here, since connectors are a long-tail game. We&#39;ve tried to make it easy to add connectors (a single python interface), and as a result over half of our connectors are contributed by the community. We expect that percentage to grow over time. This means that compared to something like Agentspace, we&#39;ll very likely be connected to all of the key tools at your company (and if we aren&#39;t, you can easily add an integration).</p>
        <p>The main thing Ireallycare about is voice mode, as that&#39;s my far preferred way of interacting with LLMs for longer backs and forths (most apps I&#39;ve seen disable a lot of other functionality during it, which I hate, btw).</p>
        <p>Two other things I would like to see are canvas mode and scheduled actions (withdecision making capability - e.g. &quot;send a notification if X happens&quot;).</p>
        <p>I assume such features are going to continue being invented, so I find extensibility to be ahugedeal. So much so that one thing I could imagine going really well would be a UI on top of Langchain, which already has most of the facilities for that!</p>
        <p>My main gripe with openwebui, in addition to it being slow is the fact that it mangles documents in the OCR step. tables that could have been understood great by an multi modal llm, just gets mangled by the ocr and lost instead of storing both a text and original representation.</p>
        <p>Being able to properly searcbin the knowlege base lime the llm does, but manually would be nice (like get recommendations for docs to add).</p>
        <p>My usecase is mostly writing, so having a integrated document refinery editor is also a nice feature list.</p>
        <p>I&#39;m probably rambling but these are my base use-cases for a llm ui I personally have found.</p>
        <p>Writing is a really common use case, and something we&#39;d like to explore more. Currently people often use Onyx for &quot;write something combining X, Y, and Z documents&quot;, but I feel that&#39;s just scratching the surface.</p>
        <p>But stoked to get alternatives to the area, will try it out once i get time soon.</p>
        <p>It’s nice to see an attempt at an end to end stack (for all that it seems this is “obvious” … there are not that many functional options) but wow we’ve forgotten the basis of making useful products. I’m hoping it gets enough time to bake.</p>
        <p>The admin side of the house has been missing a bit of love, and we have a large overhaul coming soon that I&#39;m hoping addresses some (most?) of your concerns. For now, if you&#39;d like to view documents that have been processed, you can check out the `Explorer` panel on the left.</p>
        <p>In general, I&#39;d love to hear more about what gives it that &quot;unbaked&quot; feel for you if you&#39;re up for a quick chat.</p>
        <p>Something like this could have a nice future as an open source chat framework for building custom UIs if it&#39;s well made and modular, but that isn&#39;t gonna work well with a SaaS model.</p>
        <p>&quot;What&#39;s Max&#39;s GitHub username?&quot;
&quot;I need wire transfer instructions for an incoming wire&quot;</p>
        <p>We also index competitors&#39; helpdesks and KB articles to track new features they&#39;re rolling out.
Our tech support team uses it daily because Freshdesk&#39;s AI is terrible and their internal KB search is lackluster. Onyx actually finds things.
The value isn&#39;t in being &quot;one chat to rule them all&quot; — it&#39;s in unified search across disparate systems with citations. That&#39;s not getting commoditized anytime soon.
Keep up the good work, team.</p>
        <p>It does requires having UI components for many different types of interactions (e.g. many ways to collect user input mid-session + display different tools responses like graphs and interactives). With this, people should be able to easily build complex tools/flows on top of that UI, and get a nice, single interface (no siloed tools/swapping) for free. And having this UI be open-source make this easier.</p>
        <p>And this is all made all the more important when supporting the wide range of models, even &quot;weaker&quot; open-source models.</p>
        <p>Can you call it open source if you need a subscription license to run / edit the code?</p>
        <p>- UI-based white labeling</p>
        <p>Content under backend/ee requires a license, everything else is MIT Expat.
Pretty standard stuff.</p>
        <p>&gt; Can you call it open source if you need a subscription license to run / edit the code?</p>
        <p>MIT is open source, their other stuff isn&#39;t. Pretty clear.</p>
        <p>Could you elaborate why this approach is confusing?</p>
        <p>A common &quot;trick&quot; for commercial open source software is to use a copyleft license, which restricts redistribution as part of commercial products, and to offer a paid license to get around that.</p>
        <p>[1]:https://opensource.org/osd</p>
        <p>I was responding to parent&#39;s question though: &quot;Can you call it open source if you need a subscription license to run / edit the code?&quot;</p>
        <p>I&#39;d say no. If you have the code in front of you, it shouldn&#39;t require a license to run. Even if the whole point of the open source software is to interact with a proprietary piece of software or service, you could still run it for free, it probably just wouldn&#39;t have much utility.</p>
        <p>&gt; Many people believe that the spirit of the GNU Project is that you should not charge money for distributing copies of software, or that you should charge as little as possible—just enough to cover the cost. This is a misunderstanding.</p>
        <p>&gt; Actually, we encourage people who redistribute free software to charge as much as they wish or can. If a license does not permit users to make copies and sell them, it is a nonfree license.</p>
        <p>https://www.gnu.org/philosophy/selling.html</p>
        <p>And even if the source code was only distributed to paying customers, that&#39;d likely be a temporary situation. A relevant quote:</p>
        <p>&quot;With free software, users don&#39;t have to pay the distribution fee in order to use the software. They can copy the program from a friend who has a copy, or with the help of a friend who has network access.&quot;</p>
        <p>I do read the GPLv3 such that if someone _does_ buy the code in any fashion, you must provide the source code to them for free. Relevant excerpt from section 6:</p>
        <p>&quot;[...] give anyone who possesses the object code either (1) a copy of the Corresponding Source for all the software in the product that is covered by this License, on a durable physical medium customarily used for software interchange, for a price no more than your reasonable cost of physically performing this conveying of source, or (2) access to copy the Corresponding Source from a network server at no charge.&quot;</p>
        <p>But yeah, no obligation to provide the source code for free to non-customers, fair point. Just no ability to stop customers from sharing it with non-customers. Does make sense.</p>
        <p>One of our largest users has forked the repo and has 20+ commits back to the repo of small customizations that are important for them (and that they could never get with ChatGPT Enterprise).</p>
        <p>Lots of companies we talk to value having the best model for the job (e.g. not being tied to ONLY OpenAI models for example).</p>
        <p>Compared to model provider offerings, we also (thanks to open-source contributions) cover many more existing apps when it comes to connectors.</p>
        <p>Onyx Devs:  This looks awesome, I will definitely add it to my list of things to try out... close to the top!  Thanks, and please keep it cool!</p>
        <p>- Instability when self-hosting</p>
        <p>- Hard to get in touch with sales when looking for SLA-based contracts</p>
        <p>- Cluttered product; Multiple concepts seemingly serving the same purpose (e.g. function calling vs. MCP); Most pre-MCP tools suffer from this</p>
        <p>- Trouble integrating it with OIDC</p>
        <p>- Bad docs that are mostly LLM generated</p>
        <p>Both internal RAG and web search are hard to do well, and since we&#39;ve started as an enterprise search project we&#39;ve spent a lot of time making it good.</p>
        <p>Most (all?) of these projects have UXs that are quite complicated (e.g. exposing front-and-center every model param like Top P without any explanation, no clear distinction between admin/regular user features, etc.). For broader deployments this can overwhelm people who are new to AI tools.</p>
        <p>Finally trying to do anything beyond a simple back and forth with a single tool calls isn&#39;t great with a lot of these projects. So something like &quot;find me all the open source chat options, understand their strengths/weaknesses, and compile that into a spreadsheet&quot; will work well with Onyx, but not so well with other options (again partially due to our enterprise search roots).</p>
        <p>a mobile application that has parity on the same features that ChatGPT and Claude does...</p>
        <p>Things like shortcuts to access the chat + ability to reach into the local file system are very compelling.</p>
        <p>&gt; but I’m going to start by connecting GPT-4o, Claude Sonnet 4, and Qwen to provide my team with a secure way to use them</p>
        <p>I did get a little giggle out of that because I&#39;ve never heard anyone say that hooking up 3rd party llms to anything was any way secure.</p>
        <p>The key point there is that many would do it through Azure / Bedrock + locally host the open-source models. Also, all chats / indexed data lives on-prem, and there are better guarantees around retention when using the APIs directly.</p>
        <p>I was told there would be rapid prototyping with AI. Haven&#39;t seen any of the above.</p>
        <p>Curious, it&#39;s a crowded space with other enterprise search companies like Glean and Elastic, and other companies coming in like Notion and Slack.</p>
        <p>Why should a prospect choose Onyx over the others?</p>
        <p>- &quot;pure chat&quot; experience. From our community (and personal use), we&#39;ve observed that most queries don&#39;t actually involve enterprise search. They much more likely to just require the LLMs internal knowledge (or web search / code execution). Compared to all the companies you&#39;ve mentioned, we&#39;ve spent a lot more time refining this more common flow.</p>
        <p>- Larger connector suite. As soon as one key source isn&#39;t connected, the trustworthiness of the system is dramatically decreased. You second guess &quot;is the info needed to answer this question in there?&quot; for every question. We have a community who builds out connectors for themselves, and then contribute it back for everyone to use. This allows us to cover the long-tail better than companies like Notion and Slack.</p>
        <p>- Customizability. An open-source application is the perfect middle ground between a SaaS offering and building blocks. A SaaS option doesn&#39;t allow for any customization (we have many customers who have contributed back ux enhancements, small features like guardrails, or enhanced configurations that their users want). Building blocks demand too much domain expertise (search, frontend/UX, ...) for it to be realistic for companies to build something great.</p>
        <p>In our opinion, it&#39;s a bit silly to build completely in house when you can take something like Onyx as the starting point and be &gt;95% of the way there + have a tons of bells and whistles built in.</p>
        <p>However it doesn&#39;t seem to have MinerU as a supported backend, which is hands-down the best PDF extraction tool I&#39;ve ever used (and is self-hostable on a machine with a modest GPU). Could it be added?</p>
        <p>https://github.com/opendatalab/MinerU</p>
        <p>Might have to try this out. OWUI&#39;s lagging docs has made managing my own self hosted instance a pain.</p>
        <p>PS: Your _See All Connectors_ button on the homepage is 404ing.</p>
        <p>&quot;Agents&quot; is a particular area where we feel like we&#39;re better than the alternatives (especially if you want something that effectively calls multiple tools in sequence). Curious to hear your thoughts after trying it out!</p>
        <p>1/ large connector suite + good RAG. Answers at scale is hard, and from our enterprise search roots, we&#39;ve spent a lot of time with it. It&#39;s something that many teams expect from their chat UI.</p>
        <p>2/ deep research + open-source code interpreter.</p>
        <p>3/ simpler UX. LibreChat has a lot of customizability exposed front and center to the user, which is great for the power user but can be overwhelming for someone new to using AI systems.</p>
        <p>Can you clarify the license and if this actually meets the definition of Open Source as outlined by the OSI [1] or if this is actually just source available similar to OpenWebUI?</p>
        <p>Specifically can / does this run without the /onyx/backend/ee and web/src/app/ee directories which are licensed under a proprietary license?</p>
        <p>1 -https://opensource.org/licenses</p>
        <p>We havehttps://github.com/onyx-dot-app/onyx-foss, for a fully MIT licensed version of the repo if you want to be safe about the license/feel freedom to modify every file.</p>
        <p>We are building a competing open source tool[0] with a very similar focus (strongly relying on interoperable standards like MCP; built for enterprise needs, etc.), though bootstrapping with customers rather than being VC funded. It&#39;s nice to see a competitor in the field following similar &quot;OSS Friends&quot; principles, while many of the other ones seem to have strong proprietary tendencies.</p>
        <p>(Small heads up: The &quot;view all integrations&quot; button goes to a 404)</p>
        <p>[0]https://erato.chat/</p>
        <p>Why do we have to yet again poorly copy an oversimplified UI?</p>
        <p>The value of local models comes from their huge amount of settings/control that they offer. Why must we throw that all away?</p>
        <p>Yet again, the world waits for good UI/UX for pro/prosumers with AI systems. No one is learning from ComfyUI, Automatic1111, or SillyTavern. No, LM-Studio is not actually prosumer</p>
        <p>For now, the main reasons for a prosumer to use over oobabooga/sillytavern are around the base tool set we provide and the &quot;agent loop&quot;. If you ever want to use your single chat interface to do data analysis (code interpreter), multi-step realtime research (deep research), or RAG over large scale data (hybrid search), Onyx would be a particularly good choice.</p>
        <p>The target customers are enterprises where 70% of the target users have never used an AI system before and have to go through a AI training before being allowed access to the system.</p>
        <p>And no one bothered to say anything to them?</p>
        <p>I also wouldn&#39;t pin it as chat app specific. Quite a few VC funded open core software has adopted that pattern post ~2020(?): cal.com, Dagster, Gitlab</p>
        <p>Thanks, lawyers, you make everything better!</p>
        <p>As long as you have Pricing on your website your product is not open source in the true spirit of open sourceness. It is open code for sure but it is a business and so incentive is to run it like a business which will conflate with how the project is used by the community.</p>
        <p>Btw, there is nothing wrong with that but let&#39;s be honest here if you get this funded (perhaps it already is) who are you going to align your mission with - the open source community or shareholders? I don&#39;t think you can do both. Especially if a strong competitor comes along that simply deploys the same version of the product. We have seen this story many times before.</p>
        <p>Now, this is completely different from let&#39;s say Onyx being an enterprise search product where you create a community-driven version. You might say that fundamentally it is the same code but the way it is presented is different. Nobody will think this is open-source but more of &quot;the source is available&quot; if you want to check.</p>
        <p>I thought perhaps it will benefit to share this prospective here if it helps at all.</p>
        <p>Btw, I hear good things about Onyx and I have heard that some enterprises are already using it - the open-source version.</p>
        <p>I think there can be other valid perspectives than your own.</p>
        <p>It&#39;s an MIT license. That IS open source.</p>
        <p>If they have a commercial strategy - that&#39;s a GoodThing. It means they have a viable strategy for staying in business, and keeping the project maintained.</p>
        <p>MIT == OpenSource. Pricing == Sustainable. That&#39;s a horse worth backing IMO.</p>
        <p>At the top level looks like open source but it is not really because parts (the most useful ones) of the project are not. Imagine if python was open source but the core libraries where not. You wont call this open source in the true spirit of open source. You could make the argument that at least it is sustainable because they a have now a business model. It doesn&#39;t add up.</p>
        <p>I prefer more of a honest take on software. There is nothing wrong to make money while contributing back to the community in some meaningful way or by simply being transparent. In fact this is the best kind and there are plenty of good examples.</p>
        <p>All I am saying is that when I see such projects I tend to think that in most cases they are dishonest to themselves or their communities or both.</p>
        <p>The source is available and you can do much with it, but the incentive is that this alone should not be enough.</p>
        <p>For most people, the chat is the entrypoint to LLMs, and people are growing to expect more and more. So now it might be basic chat, web search, internal RAG, deep research, etc. Very soon, it will be more complex flows kicked off via this interface (e.g. cleaning up a Linear project). The same &quot;chat UI&quot; that is used for basic chat must (imo) support these flows to stay competitive.</p>
        <p>On the engineering side, things like Deep Research are quite complex/open-ended, and there can be huge differences in quality between implementations (e.g. ChatGPTs vs Claude). Code interpreter as well (to do it securely) is quite a tricky task.</p>
        <p>That being said, I think there is an opportunity for them to discover and serve an important enterprise use case as AI in enterprise hits exponential growth.</p>
        <p>On another axis, if you are able to offer BYOK deployments and the customers have huge staff with low usage, it&#39;s pretty easy to compete with the big players due to their high per-seat pricing.</p>
        <p>The common trend we&#39;ve seen is that most of these other projects are okay for a true &quot;just send messages to an AI and get responses&quot; use case, but for most things beyond that they fall short / there a lot of paper cuts.</p>
        <p>For an individual, this might show up when they try more complex tasks that require multiple tool calls in sequence or when they have a research task to accomplish. For an org, this might show up when trying to manage access to assistants / tools / connected sources.</p>
        <p>Our goal is to make sure Onyx is the most advanced and mature option out there. Ithinkwe&#39;ve accomplished that, so if there&#39;s anything missing I&#39;d love to hear about it.</p>
        <p>I have used vercel for several projects and I&#39;m not tied to it, but would like to understand how onyx is comparable.</p>
        <p>Benefits for my use cases for using vercel have been ease of installation, streaming support, model agnosticity, chat persistence and blob support. I definitely don&#39;t like the vendor lock in, though.</p>
        <p>we have all of those!</p>
        <p>&gt; how onyx is comparable</p>
        <p>For an AI-powered research assistant, Onyx might just work out of the box. We have ~45 connectors to common apps (https://github.com/onyx-dot-app/onyx/blob/main/backend/onyx/...), integrations with the most popular web search providers (https://github.com/onyx-dot-app/onyx/blob/main/backend/onyx/...), and a built in tool calling loop w/ deep research support (https://github.com/onyx-dot-app/onyx/blob/main/backend/onyx/...). If you wanted to customize, you could pretty easily tweak this / add additional tools (or even rip this out completely and build your own agent loop).</p>
        <p>I could just have kept this &quot;negative&quot; thought to myself, but maybe other lurkers think the same. Something for you guys to have in mind. Good luck!</p>
        <p>How we think about it: the chat product should be completely open-source and free (forever). To that end we&#39;ve moved features like SSO (that used to be &quot;enterprise&quot;) to be MIT licensed. The chat interface is something pretty much every team needs (be it a proprietary or open-source solution). You can think of this like Apache Spark for Databricks or Ray for Anyscale.</p>
        <p>Also, as other folks have pointed out in the thread, there are quite a few other open source options out there. So there&#39;s a a ton of outside pressure for our open-source only offering to be very competitive. We hope this reduces the &quot;enshitification&quot; risk that you speak of.</p>
    </section>
    
    <footer>
        <a href="https://news.ycombinator.com/item?id=46045987" target="_blank">阅读原文</a>
    </footer>
</article>
```

**原文链接：** [https://news.ycombinator.com/item?id=46045987](https://news.ycombinator.com/item?id=46045987)

---
